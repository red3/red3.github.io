<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="author" content="Harry" />
    
    <title>Scrapy+MySQL+PHP+Swift开发攻略系列（二）爬虫篇</title>
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link href="/atom.xml" rel="alternate" title="red3 harry" type="application/atom+xml" />
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="/media/css/style.css">
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/retina.js/1.3.0/retina.min.js"></script>
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
    <script type="text/javascript"> hljs.initHighlightingOnLoad(); </script>
  </head>
  <body>
      <div id="main" role="main">
        <header>
          <div id="header">
            <h1><a title="red3 harry" class="" href="/">red3 harry</a></h1>
          </div>
          <nav>
            
            <span><a title="Archive" href="/archive.html"><i class="fa fa-list-ul"></i></a></span>
            
            <span><a title="Tags" href="/tags.html"><i class="fa fa-tags"></i></a></span>
            
            <span><a title="About" href="/about.html"><i class="fa fa-user"></i></a></span>
            
            <span><a title="Gallery" href="http://redthree.lofter.com"><i class="fa fa-film"></i></a></span>
            
            <span><a title="Subscribe" href="/atom.xml"><i class="fa fa-rss"></i></a></span>
            
          </nav>
        </header>
        <div id="content">
        <article>
  <section class="title">
    <h2>Scrapy+MySQL+PHP+Swift开发攻略系列（二）爬虫篇 </h2>
  </section>
  <section class="meta">
  <span class="time">
    <time datetime="2015-08-29">2015-08-29</time>
  </span>
  
  <span class="tags">
    
    <a href="/tags.html#Linux" title="Linux">#Linux</a>
    
    <a href="/tags.html#Scrapy" title="Scrapy">#Scrapy</a>
    
    <a href="/tags.html#Swift" title="Swift">#Swift</a>
    
  </span>
  <!-- BEGIN this would not work on any other domain -->
  <span
    class           = "like-wrapper"
    like-shortname  = 'gopherwood'
    like-identifier = ''
    like-name       = 'Scrapy+MySQL+PHP+Swift开发攻略系列（二）爬虫篇'
    like-btn        = '&#xf087;'
    like-link       = '/2015/08/29/fullstack-of-Scrapy+MySQL+PHP+Swift2.html'
    ></span>
  <script type="text/javascript">
    var l = document.createElement('script');
    l.type = 'text/javascript'; l.async = true; l.src = 'http://www.like-btn.com/javascript/widget.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(l);
  </script>
  <!-- END this would not work on any other domain -->
  
  </section>
  <section class="post">
  <h2 id="section">系列目录</h2>

<p>你可以从这个地方做一个快速跳转。</p>

<ul>
  <li><a href="http://blog.coderharry.com/2015/08/08/fullstack-of-Scrapy+MySQL+PHP+Swift.html">Scrapy+MySQL+PHP+Swift开发攻略系列（一）之前言篇</a></li>
  <li><a href="">Scrapy+MySQL+PHP+Swift开发攻略系列（二）之爬虫篇</a></li>
  <li><a href="">Scrapy+MySQL+PHP+Swift开发攻略系列（三）之数据库MySQL篇</a></li>
  <li><a href="">Scrapy+MySQL+PHP+Swift开发攻略系列（四）之爬虫被封+爬虫自动运行篇</a></li>
  <li><a href="">Scrapy+MySQL+PHP+Swift开发攻略系列（五）之API篇</a></li>
  <li><a href="">Scrapy+MySQL+PHP+Swift开发攻略系列（六）之RESTAPI篇</a></li>
  <li><a href="">Scrapy+MySQL+PHP+Swift开发攻略系列（七）之Swift篇</a></li>
</ul>

<h2 id="scrapy">安装Scrapy</h2>
<p>爬虫框架我选择用Python写的Scrapy。</p>

<p>当然准备工作是确保你的Mac安装了<code>commandline</code>和<code>pip</code>.</p>

<ul>
  <li>安装<code>commandline</code>可以通过直接安装<code>Xcode</code>或者在终端运行<code>xcode-select --install</code>命令安装。</li>
  <li>安装<code>pip</code>：遵从官方的这个<a href="https://pip.pypa.io/en/stable/installing.html#install-pip">步骤</a></li>
</ul>

<p>然后通过<code>pip</code>安装<code>Scrapy</code>.</p>

<pre><code>sudo pip install scrapy
</code></pre>

<p>如果你安装成功，请直接跳到下一节。我在公司电脑的环境（OS X 10.10 Python2.7.10）以及家里的电脑的环境（OS X 10.11 Python2.7.10）下安装会因为类似<code>libxml not found</code>的原因失败，通过以下方式解决：</p>

<pre><code>brew install libxml2
brew install libxslt
brew link libxml2 --force
brew link libxslt --force
</code></pre>

<p>安装成功以后，如果<code>scrapy startproject xxx</code>报类似的错<code>ImportError: cannot import name xmlrpc_client</code>，通过以下方式解决：</p>

<pre><code>sudo rm -rf /Library/Python/2.7/site-packages/six*
sudo rm -rf /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six*
sudo pip install six
</code></pre>

<p>如果以上方法不能失效，请参考<a href="http://stackoverflow.com/questions/30964836/scrapy-throws-importerror-cannot-import-name-xmlrpc-client">这个链接</a></p>

<h2 id="section-1">创建爬虫项目</h2>

<p>通过下面这个命令生成一个爬虫项目：</p>

<pre><code>scrapy startproject dbmeizi
</code></pre>

<p>然后我们会看到<code>scrapy</code>已经为我们生成了一个工程。这个工程大概是这个结构</p>

<pre><code>dbmeizi
|__ scrapy.cfg
|
|__	 dbmeizi
	 |__ __init__.py
	 |__ items.py
	 |__ pipelines.py
	 |__ settings.py
	 |__ spiders
</code></pre>

<p>下面分别解释下各个文件：</p>

<ul>
  <li><code>items.py</code> - item相当于是mvc中的model，在items里我们定义了自己需要的模型</li>
  <li><code>piplines.py</code> - pipline俗称管道，这个文件主要用来把我们获取的item类型存入MySQL</li>
  <li><code>settings.py</code> -  在这个文件里面配置整个工程的一些设置。例如MySQL的数据库名，数据库地址和数据库端口号等等。</li>
  <li><code>spiders</code> - 这个文件夹存放爬虫文件。</li>
</ul>

<p>至此，我们就可以正式开始我们的编码工作了。</p>

<h2 id="modelitem">定义Model层（Item）</h2>

<p>首先我们想确定一个网站上的图片包含哪些信息，要解决这个问题，就需要打开这个网页使用<code>开发者工具</code>(快捷键<code>option+command+i</code>), 使用<code>页面选择器</code>(开发者工作左上角的放大镜图标)选择一张图片，效果如下:</p>

<p><img src="/assets/2015/img_spiders01.png" alt="" /></p>

<p>可以看出，我们选中的<code>div</code>块中包含了我们想要的最基本的资料。这个过程，其实就是我们爬虫的一个工作原理，通过网页元素找到我们想要的内容，只不过现在我们是手动查找，等发现规律，我们就通过爬虫程序自动爬取内容。</p>

<p>所以item.py里面是这个样子：</p>

<pre><code>// 需要注意的是这个文件的默认模板样式可能根据scrapy版本不同略有不同，依照默认模板样式加入我们的自定义字段就可

import scrapy

class DbmeiziItem(scrapy.Item):
	# define the fields for your item here like:
	# name = scrapy.Field()
	imgsrc = scrapy.Field()
	title = scrapy.Field()
	topic_link = scrapy.Field()
	star_count = scrapy.Field()
	update_time = scrapy.Field()
	pass
</code></pre>

<p>相当于我们继承自类Item创建了我们自己的MeiziItem，然后我们的自定义类有5个属性，<code>star_count</code>是设计用来让用户点赞的，最后的<code>update_time </code>可以用来记录修改时间。</p>

<h2 id="spider">编写爬虫(Spider)</h2>

<p>Spider是我们用于从单个网站(或者一些网站)爬取数据的类。</p>

<p>其中包含了一个用于下载的初始URL，如何跟进网页中的链接以及如何分析页面中的内容， 提取生成<code>item</code>的方法。</p>

<p>在<code>spiders</code>文件夹下新建<code>dbmeizi_scrapy.py</code>文件。
这个文件里面是这个样子：</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">scrapy</span> <span class="kn">import</span> <span class="n">Spider</span>
<span class="kn">from</span> <span class="nn">scrapy.selector</span> <span class="kn">import</span> <span class="n">Selector</span>
<span class="kn">from</span> <span class="nn">dbmeizi.items</span> <span class="kn">import</span> <span class="n">DbmeiziItem</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="k">class</span> <span class="nc">dbmeiziSpider</span><span class="p">(</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s">&quot;dbmeiziSpider&quot;</span>
    <span class="n">allowed_domin</span> <span class="o">=</span><span class="p">[</span><span class="s">&quot;dbmeinv.com&quot;</span><span class="p">]</span>
    <span class="n">strArray</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
        <span class="nb">str</span> <span class="o">=</span> <span class="s">&quot;http://www.dbmeinv.com/?pager_offset=</span><span class="si">%d</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">i</span>
        <span class="n">strArray</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="n">strArray</span>
            
    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">divResults</span> <span class="o">=</span> <span class="n">Selector</span><span class="p">(</span><span class="n">response</span><span class="p">)</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;//div[@class=&quot;img_single&quot;]&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">div</span> <span class="ow">in</span> <span class="n">divResults</span><span class="p">:</span>
            <span class="n">item</span> <span class="o">=</span> <span class="n">DbmeiziItem</span><span class="p">()</span>
            <span class="n">href</span> <span class="o">=</span> <span class="n">div</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;.//a&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">img</span> <span class="o">=</span> <span class="n">div</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;.//img&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">item</span><span class="p">[</span><span class="s">&#39;topic_link&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">href</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">item</span><span class="p">[</span><span class="s">&#39;title&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;@title&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span> 
            <span class="n">item</span><span class="p">[</span><span class="s">&#39;imgsrc&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;@src&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">item</span><span class="p">[</span><span class="s">&#39;star_count&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">item</span><span class="p">[</span><span class="s">&#39;update_time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            <span class="k">yield</span> <span class="n">item</span></code></pre></div>

<p>需要解释的几点概念：</p>

<ul>
  <li><code>allowed_domin </code> - 指定在哪个网站爬东西</li>
  <li><code>start_urls</code> - 包含了Spider在启动时进行爬取的url列表。因此，第一个被获取到的页面将是其中之一。后续的URL则从初始的URL获取到的数据中提取</li>
  <li><code>parse </code>方法 - 继承自父类，每个初始URL完成下载后生成的<code>Response</code>对象将会作为唯一的参数传递给该函数。该方法负责解析返回的数据(response data)，提取数据(生成<code>item</code>)以及生成需要进一步处理的URL的<code>Request</code>对象。可以想象成这个方法一开始拿到的数据就是整个网页的html代码，我们要通过各种过滤，拿到最终我们感兴趣的内容</li>
  <li><code>xpath</code> - 解析数据的时候我们用到这个东西，关于它的详细用法，移步这个<a href="http://www.w3school.com.cn/xpath/index.asp">网址</a></li>
</ul>

<p>最终，爬虫通过上面的代码爬到我们感兴趣的内容了，通过这些内容为<code>item</code>赋值。</p>

<h2 id="section-2">运行爬虫</h2>
<p>到现在为止，这个爬虫就可以正常工作了。在工程的根目录下执行如下命令：</p>

<pre><code>scrapy crawl dbmeiziSpider
</code></pre>

<p>不出意外的话，会看见下面的画面：</p>

<p><img src="http://redharry.b0.upaiyun.com/pic/spider_show01.gif" alt="" /></p>

<p>大功告成。</p>

<p>刚才提到不出意外的情况，那么出意味的情况是什么呢，当然就是这个网站把我们屏蔽了，我们爬不到他的数据了。针对这种情况，会在系列（四）中给出解决方案。</p>

<h2 id="section-3">最后</h2>

<p>按照惯例，放上源码地址：</p>


  </section>
  
</article>

        </div>
        <footer>
          <div>
            
            &copy; 2015 ~ 2015 Harry | powered by jekyll | themed by <a href="http://lhzhang.com" title="sext vi">sext vi</a> | fork <a href="https://github.com/red3" title="fork me">me</a>
          </div>
        </footer>
      </div> <!-- main -->
  </body>
</html>
